
\newcommand{\ignore}[1]{}

% The Introduction should contain the followings.

% 1. A meaningful example extracted from RTE data sets. This example
% demonstrates the need of relation detection applied directly to
% textual inference.

% 2. Open and traditional relation extraction and their limitation in
% natural language inference.

% 3. Natural logic for textual inference.

% 4. Our system.

% 5. Table of content of the paper.

Many data and knowledge management problems require some sort of
textual inference. These range from expansion and query interpretation
in information retrieval to query schema matching and question
answering. Textual Inference, in turn, requires the use of large
amounts of background knowledge. For example, it may be important to
know that a {\em blue Toyota} is not a {\em red Toyota} nor a {\em
  blue Honda} but that all are cars, and even Japanese made cars.

The fundamental problem expressed here is that of recognizing basic
relations between two given concepts. This view of recognizing
relations is different from the Open Information Extraction effort
\cite{BCSBE07} and On-Demand Information Extraction \cite{Sekine06},
which aim to extract large databases of open-ended facts and build the
two concepts occurring together in some local context. It is also
different from the supervised relation extraction\cite{RothYi04}
effort which requires additional supervised data to learn new
relations.

\ignore{ This is a different problem than variations of
relation extraction studied in the literature
\cite{banko-etzioni:2008:ACLMain} that aim at extracting
relations between entities that co-occur in a given snippet of
text. While the extraction of knowledge of this sort has also
been discussed in the literature, it has been studied mostly in
the context of large scale knowledge acquisition - extract all
{\em easy to find} facts in a given
corpus~\cite{banko-etzioni:2008:ACLMain,davidov-rappoport:2008:ACLMain2,pacsca-vandurme:2008:ACLMain,bunescu-mooney:2007:ACLMain}.
This knowledge is typically existential; e.g., while it is true
that A is of type B, say, it is not clear if it is commonly B.
}

Moreover, a textual inference system that needs to know if
concepts {\em A} and {\em B} are related, and how, cannot benefit from the
large body of literature on knowledge acquisition that has
extracted all {\em easy to find} facts in a given
corpus~\cite{banko-etzioni:2008:ACLMain,davidov-rappoport:2008:ACLMain2,pacsca-vandurme:2008:ACLMain},
%%% Need to put in cited.bib and change the style
since it will know of {\em A} and {\em B} only if they have occurred
in an explicit way and in close proximity in a sentence. Indeed, we
know of no successful application of the large scale existential
knowledge acquisition efforts to textual inference.


In the context of Textual
Inference~\cite{DaganGlMa06,HaghighiNMa05,BGPRS05}, it has been
argued, e.g. in \cite{maccartney-manning:2008:PAPERS} that many
inferences are largely compositional and depend on the ability of the
models to recognize specific relations between concepts such as
entities, noun phrases, etc. For example, it is often necessary to
know of an {\em ancestor} relation and its directionality in order to
deduce that a statement with respect to the {\em child} (e.g., {\em
  cannabis}) holds for an {\em ancestor} (e.g.,{\em drugs}). This is
illustrated in the following example, taken from the RTE4 test data:

{\small
  \begin{quote}

    {\bf T}: Nigeria's National Drug Law Enforcement Agency (NDLEA)
    has seized 80 metric tonnes of {\em cannabis} in one of its
    largest ever hauls, officials say.

    {\bf H}: Nigeria seizes 80 tonnes of {\em drugs}.
  \end{quote}
}

Similarly, it is often important to know of a {\em sibling} relation
to infer that a statement about {\em Taiwan} may {\em contradict} an
identical statement with respect to {\em Japan} (at least, without
additional information) since these are {\em different}
countries. This is illustrated in the following example from RTE4 test
data:

{\small
\begin{quote}

  {\bf T}: A strong earthquake struck off the southern tip of {\em
    Taiwan} at 12:26 UTC, triggering a warning from Japan's
  Meteorological Agency that a 3.3 foot tsunami could be heading
  towards Basco, in the Philippines.

  {\bf H}: An earthquake strikes {\em Japan}.
\end{quote}
}

This paper proposes to address the problem of relation identification
and classification in a form that is directly applicable to textual
inference.
%
Specifically, our system accepts two input concepts as arguments
(these could be entities or noun phrases) and identifies the relation
between them \ignore{along with its possible label}. For example, we
identify that {\em global warming} and {\em food crisis} are in a {\em
  sibling} relation, and the concept of {\em economic problems} is in
an {\em ancestor} relation with both of them.

We focus here on the {\em ancestor} relation and the {\em
sibling} relation that were identified as key relations also
in \cite{maccartney-manning:2008:PAPERS} (the {\em sibling}
relation is called an {\em alternation} there, and our {\em
ancestor} relation is called {\em forward entailment} and {\em
backward entailment}). Following the logic developed there, we
expect that the resource we develop in this work can be used
compositionally to support robust textual inference.

\ignore{ Our approach can discover whether two input entities
pose an
  alternation (or non-exhaustive exclusion) relation ({\em red} $|$
  {\em green}), forward entailment ({\em Mel Gibson} $\sqsubset$ {\em
    actor}), reverse entailment ({\em flower} $\sqsupset$ {\em lily}),
  or independence ({\em Boeing 747} $\#$ {\em Valentine}). }

We develop an approach that makes use of Wikipedia and that given a
pair of concepts, can, on the fly, recognize and classify the relation
between these concepts. Because Wikipedia is vast, rapidly-changing
resource, our approach needs to take into account that it is very
noisy and non-uniform. Our algorithmic approach therefore treats
Wikipedia and its category structure as an open resource and uses
statistical text mining techniques to gather robust information from
this noisy resource. For example, the concept {\em Ford} appears many
times in Wikipedia and is part of a large number of categories. As a
{\em president}, mentions of {\em Ford} are inconsistent with
mentions of other presidents. However, {\em Ford} appears also in other
senses, related to the {\em car} industry, for example.  We need to
disambiguate it and determine which category it belongs to and, within
this category, which specific concept is intended.
%
In order to disambiguate it, we make use of the context provided by
the concept pair---{\em Ford} in ({\em Ford}, {\em Nixon}) is probably
different than the one in ({\em Ford}, {\em Chevrolet}) as well as the
one in ({\em Ford}, {\em Iacocca}).

Textual inference is driven by background knowledge. Therefore, the
notion of {\em prominence} is essential in supporting textual
inference. Most people know that {\em Michael Jordan} is a former NBA
player, but they most likely do not know the {\em Michael Jordan} who
attends school with the authors.  Consequently, unless additional
knowledge is given, a textual inference system should assume that {\em
  Michael Jordan} is a basketball player. This is the reason we use
Wikipedia as our background knowledge source. Moreover, under the
assumption that in textual inference applications we are in search of
some notion of ``common sense'' knowledge, we make use of a notion of
prominence with respect to a given text collection (in this case, with
respect to Wikipedia itself). Clearly, while Wikipedia has broad
coverage that is sufficient for many applications, one may want to go
beyond it in some cases. We suggest a simple but efficient technique
accomplish this that makes use of the web, and show its effectiveness
when at least one of the target concepts is not mentioned in
Wikipedia.

We measure the performance of our system over a large number of
pairs chosen from over 40 semantic classes. We compare it with other
large scale efforts to identify relations between concepts. For
example we show that, even when all concepts are covered by the
{\em extended WordNet}~\cite{Snow2006}, our system still
significantly outperforms that system.
%
%We also show examples indicating the contribution of our
%relation identification to textual inference.

The key contributions of this paper are (i) the definition of a
relation identification problem that is directly relevant to
supporting textual inference and (ii) the development of a
robust and accurate machine learning based approach to address
this problem. We show that this approach has significantly
better coverage and accuracy than other approaches, which can
only identify relations between concepts that occur in an
explicit way and in close proximity or other Wikipedia-based
approaches. Notably, our algorithmic approach is trained with a
small number of annotated examples and generalizes well across
semantic classes.

\ignore{The rest of this paper is organized as follows. In
Section~\ref{sec:relatedwork}, we briefly mention about
previous work that inspired our approach.
Section~\ref{sec:approach} formalizes the problem and describes
our algorithmic approach to relation detection and
classification. Our experiments and results are described in
Section \ref{sec:experiments}. Discussion and future work are
in Section \ref{sec:discussion}.}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "jupiter"
%%% End: 
